{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Convolution2D, Flatten, Dropout,GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import models,optimizers\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from attention import AttentionLayer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import keras\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(history):\n",
    "        \n",
    "    # Accuracy\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    #plt.savefig('images/accuracy.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    #plt.savefig('images/loss.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"./data/akac_gen.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(datadir, delimiter =\"\\t\", header = 0)\n",
    "print(list(dataset.columns))\n",
    "dataset = dataset.sample(frac=1,random_state=777)  # row 전체 shuffle\n",
    "\n",
    "SNPs = ['rs2235375','rs1044516','rs11204737','rs1044516','rs7715100','rs3917192','rs2235371']\n",
    "snps = ['rs906830', 'rs1537514', 'rs4252328', 'rs2235371', 'rs481931', 'rs3771485', 'rs4252328', 'rs9651118', 'rs11796677', 'rs2295221']\n",
    "\n",
    "dataset.head()\n",
    "del_list = [\"famid\", \"pid\", \"fatid\", \"motid\", \"sex\",\"rs12089548\",\"rs11466414\"]\n",
    "for i in del_list:\n",
    "    del dataset[i]\n",
    "\n",
    "y_train = pd.to_numeric(dataset['affected']) -1\n",
    "del dataset['affected']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils import to_categorical\n",
    "#y_train_np = to_categorical(y_train_np)\n",
    "#print(y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./Ensemble/10snp2_ann.h5\")\n",
    "#model.compile(loss='mse', optimizer='adam', metrics=[\"accuracy\"])\n",
    "#model.evaluate(x_train_np, y_train_np, batch_size=200, verbose=2)\n",
    "#model.evaluate(x_test_np, y_test_np, batch_size=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = keras.models.load_model(\"./Ensemble/10snp1_ann-70-0.63.h5\")\n",
    "model1 = keras.models.load_model(\"./Ensemble/10snp1_ann_new.h5\")\n",
    "model2 = keras.models.load_model(\"./Ensemble/10snp2_ann-87-0.63.h5\")\n",
    "model3 = keras.models.load_model(\"./Ensemble/10snp3_ann-70-0.65.h5\")\n",
    "model4 = keras.models.load_model(\"./Ensemble/10snp4_ann-60-0.60.h5\")\n",
    "model5 = keras.models.load_model(\"./Ensemble/10snp5_ann-99-0.68.h5\")\n",
    "model6 = keras.models.load_model(\"./Ensemble/10snp6_ann-91-0.68.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1,model2,model3,model4,model5,model6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"./model/16snp_ann-196-0.63.h5\")\n",
    "#test_loss, test_acc = model1.evaluate(x_train_np, y_train_np, batch_size=200, verbose=2)\n",
    "predict_test =np.zeros((62,1))\n",
    "predict_train =np.zeros((200,1))\n",
    "raw_output_test=[]\n",
    "raw_output_train=[]\n",
    "num_train =200\n",
    "class CustomStopper(keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, monitor='val_accuracy',patience=50, verbose=1,restore_best_weights=True, mode='auto', start_epoch=20):# add argument for starting epoch\n",
    "        super(CustomStopper, self).__init__(monitor=monitor,patience=patience,mode=mode,verbose=verbose,restore_best_weights=restore_best_weights)\n",
    "        self.start_epoch = start_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.start_epoch:\n",
    "            super().on_epoch_end(epoch, logs)\n",
    "SNPs = [['rs7078160','rs3753582','rs2235373','rs1429591','rs1801133','rs906830','rs2013162','rs1044516','rs3917192','rs7103685'],\n",
    "           ['rs2235373','rs2013162','rs1044516','rs11204737','rs595918','rs16873348','rs3753582','rs2284791','rs3917192','rs7715100'],\n",
    "           ['rs3917192', 'rs16873348', 'rs2013162', 'rs1044516', 'rs2284791', 'rs9651118', 'rs1429591', 'rs7103685', 'rs1801133', 'rs17317411'],\n",
    "           ['rs3917192', 'rs16873348', 'rs481931', 'rs3771485', 'rs3755377', 'rs9651118', 'rs595918', 'rs7103685', 'rs1801133', 'rs2013162'],\n",
    "           ['rs906830', 'rs1537514', 'rs4252328', 'rs2235371', 'rs481931', 'rs3771485', 'rs2013162', 'rs9651118', 'rs11796677', 'rs2295221'],\n",
    "       ['rs3917192', 'rs16873348', 'rs2013162', 'rs1044516', 'rs7078160', 'rs9651118', 'rs1429591', 'rs7103685', 'rs1801133', 'rs595918']]\n",
    "print(SNPs[0])\n",
    "\n",
    "#raw_output_test.append(y_test_np)\n",
    "#raw_output_train.append(y_train_np)\n",
    "\n",
    "for i,j in zip(models,range(len(models))):\n",
    "    X_train = dataset[SNPs[j]]\n",
    "    x_train_np = np.array(X_train)[:num_train].astype(\"float\")\n",
    "    x_test_np = np.array(X_train)[num_train:].astype(\"float\")\n",
    "    y_train_np = np.array(y_train)[:num_train].astype(\"float\")\n",
    "    y_test_np = np.array(y_train)[num_train:].astype(\"float\")\n",
    "    \n",
    "    i.evaluate(x_train_np, y_train_np, batch_size=200, verbose=2)\n",
    "    i.evaluate(x_test_np, y_test_np, batch_size=100, verbose=2)\n",
    "    predict_test+=i.predict(x_test_np, batch_size=100)\n",
    "    predict_train+=i.predict(x_train_np, batch_size=100)\n",
    "    raw_output_test.append(i.predict(x_test_np, batch_size=100))\n",
    "    raw_output_train.append(i.predict(x_train_np, batch_size=100))\n",
    "    \n",
    "threshold = 5.5\n",
    "print('test auc')\n",
    "print(roc_auc_score(y_test_np, predict_test))\n",
    "print('train auc')\n",
    "print(accuracy_score(y_train_np, np.round(predict_train/threshold,0)))\n",
    "print('test acc')\n",
    "print(accuracy_score(y_test_np, np.round(predict_test/threshold,0)))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_np, np.round(predict_test/threshold,0)).ravel()\n",
    "specificity = tn/(tn+fp)\n",
    "sensitivity = tp/(tp+fn)\n",
    "print('specificity')\n",
    "print(specificity)\n",
    "print('sensitivity')\n",
    "print(sensitivity)\n",
    "\n",
    "#['rs2013162', 'rs595918', 'rs16873348', 'rs2235373', 'rs2284791', 'rs2073247', 'rs1044516', 'rs11204737', 'rs3917192', 'rs7715100']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### print(raw_output_test[0].shape)\n",
    "arr = np.array(raw_output_test).squeeze()\n",
    "print(np.expand_dims(y_test_np,axis=0).shape)\n",
    "arr = np.append(arr,y_test_np.reshape(1,62), axis=0)\n",
    "print(arr.shape)\n",
    "df_out = pd.DataFrame(np.transpose(arr))\n",
    "df_out.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test_np, np.round(predict_test/6,0), target_names=['0','1'], digits=4))\n",
    "print(classification_report(y_test_np, np.round(raw_output_test[1],0), target_names=['0','1'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix2(name,actual, predicted, classes, normalize=True, title='Confusion Matrix', cmap=plt.cm.viridis, dpi=150):\n",
    "    #conf_matrix = pd.crosstab(actual, predicted)  # confusion_matrix(actual, predicted)\n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "    conf_matrix = confusion_matrix(actual, predicted)\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] *100\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(conf_matrix, interpolation='nearest', cmap=cmap)  # , cmap=plt.cm.Greens\n",
    "    #plt.title(title, size=12)\n",
    "    plt.colorbar(fraction=0.05, pad=0.05)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    #tick_marks = np.arange(len(classes))\n",
    "    #plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.xticks(np.arange(len(classes)), classes)\n",
    "    plt.yticks(np.arange(len(classes)), classes)\n",
    "    plt.ylim( len(classes) - 0.5,-0.5)\n",
    "    #plt.yticks(np.arange(8), ('C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7'))\n",
    "    #plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = conf_matrix.max() / 2.\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            plt.text(j, i, format(conf_matrix[i, j], fmt),\n",
    "                     ha=\"center\", va=\"center\", color=\"white\" if conf_matrix[i, j] > thresh else \"black\")  #horizontalalignment\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name, dpi=dpi)\n",
    "    \n",
    "    return plt\n",
    "   \n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.grid(False)\n",
    "    #plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 150\n",
    "print(confusion_matrix(y_train_np, np.round(predict_train/5.5,0)))\n",
    "plot_confusion_matrix2(name =\"./confusion_10.png\".format(dpi),actual = y_test_np, predicted =np.round(predict_test/6,0), classes =['0','1'], cmap = 'Blues', dpi=dpi )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "\n",
    "nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(y_test_np, predict_test)\n",
    "t, o, _ = roc_curve(y_test_np, raw_output_test[4])\n",
    "print(roc_auc_score(y_test_np, raw_output_test[4]))\n",
    "print(nn_fpr_keras)\n",
    "print(nn_tpr_keras)\n",
    "print(t)\n",
    "print(o)\n",
    "auc_keras = auc(nn_fpr_keras, nn_tpr_keras)\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"1 - Specificity\")\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.title('10 SNPs AUC')\n",
    "plt.plot([0,0.0588,0.1176,0.2941,0.4705,0.5882,1], [0,0.3333,0.4222,0.8888,0.9333,0.9777,1], label='GANNET(0.882)',color='r')\n",
    "plt.plot([0,0.1176,0.1764,0.2941,0.4117,0.7647,0.9411,1], [0,0.1555,0.3111,0.8444,0.8444,0.9555,0.9777,1], label='ANN(0.714)',color='C1')\n",
    "plt.plot([0,0.0839,0.2027,0.3986,0.5104,0.8041,1], [0,0.2100,0.4201,0.6302,0.7310,0.9495,1], label='PRS(0.657)', color = 'C8')\n",
    "plt.plot([0.,0.40740741,1.], [0.,0.57142857,1.], label='RF(0.597)',color='C2')\n",
    "plt.plot([0.,0.25925926,1.], [0.,0.62857143,1.], label='SVM(0.685)',color='C4')\n",
    "plt.plot([0.,0.2962963,1.], [0.,0.54285714,1.], label='XGB(0.623)',color='C0')\n",
    "plt.plot([0.,0.3333,1.], [0.,0.57,1.], label='LR(0.619)', color = 'C5')\n",
    "plt.plot([0.,0.4074,1.], [0.,0.5429,1.], label='LGBM(0.568)', color = 'C6')\n",
    "plt.plot([0.,0.2962,1.], [0.,0.5714,1.], label='ADA(0.638)', color = 'C9')\n",
    "\n",
    "\n",
    "plt.legend(loc='best',frameon=False, prop={'size': 8})\n",
    "plt.savefig(\"./figure/10snp_roc.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"1 - Specificity\")\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.title('10 SNPs AUC')\n",
    "plt.plot([0,0.0588,0.1176,0.2941,0.4705,0.5882,1], [0,0.3333,0.4222,0.8888,0.9333,0.9777,1], label='GANNET(0.882)',color='r')\n",
    "plt.plot([0,0.1176,0.1764,0.2941,0.4117,0.7647,0.9411,1], [0,0.1555,0.3111,0.8444,0.8444,0.9555,0.9777,1], label='ANN(0.714)',color='C1')\n",
    "plt.plot([0,0.0839,0.2027,0.3986,0.5104,0.8041,1], [0,0.2100,0.4201,0.6302,0.7310,0.9495,1], label='PRS(0.657)', color = 'C8')\n",
    "plt.plot([0.,0.40740741,1.], [0.,0.57142857,1.], label='RF(0.597)',color='C2')\n",
    "plt.plot([0.,0.25925926,1.], [0.,0.62857143,1.], label='SVM(0.677)',color='C4')\n",
    "plt.plot([0.,0.2962963,1.], [0.,0.54285714,1.], label='XGB(0.613)',color='C0')\n",
    "\n",
    "\n",
    "plt.legend(loc='best',frameon=False, prop={'size': 9})\n",
    "plt.savefig(\"./figure/10snp_roc.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr):\n",
    "    m = np.argmax(arr)\n",
    "    arr = arr - m\n",
    "    arr = np.exp(arr)\n",
    "    return arr / np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 15\n",
    "outputs = model.predict(x_test_np[:])\n",
    "print(y_test_np[num])\n",
    "#print(outputs[0])\n",
    "model_outputs = np.array(outputs[0])\n",
    "attention_outputs = outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "sav_ind = []\n",
    "for t, k in zip(y_test_np, np.squeeze(np.round(model_outputs))):\n",
    "    if(t == k):\n",
    "        sav_ind.append(index)\n",
    "    index+=1\n",
    "print(sav_ind)\n",
    "print(list(dataset.columns))\n",
    "\n",
    "att = np.zeros(shape=(92,1))\n",
    "index =0\n",
    "for i in attention_outputs:\n",
    "    if index in sav_ind:\n",
    "        att+=np.expand_dims(np.array(attention_outputs[4][:]),axis=1)\n",
    "    #att+=np.expand_dims(np.array(attention_outputs[4][:]),axis=1)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(att)\n",
    "#print(np.where(np.squeeze(att/np.amax(att))==1))\n",
    "sorted_idx = sorted(range(len(att)),key=lambda x:att[x])\n",
    "att = [att[i] for i in sorted_idx ][::-1]\n",
    "snps_list = [list(dataset.columns)[i] for i in sorted_idx ][::-1]\n",
    "best_snp = np.where(np.squeeze(att/np.amax(att))==1)\n",
    "for i in best_snp[0]:\n",
    "    print(snps_list[i])\n",
    "print(snps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(np.squeeze(att/np.amax(att)))),np.squeeze(att/np.amax(att)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
